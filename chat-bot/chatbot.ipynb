{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "To demonstrate that the estimation performance of a large language model can be greatly improved without any further training, this notebook takes an older model from OpenAI and data that is not likely available in its training. Eventually the inference of the vanilla modus and the enhanced version are compared. In order to avoid that the data is present in the model's training data, a relatively new and non-popular topic is chosen.\n",
    "\n",
    "The data will be about Zynthian user guides. Zynthian (https://zynthian.org/) is a young open source project that turns a Raspberry Pi into a synthesizer instrument.\n",
    "\n",
    "The Zynthian user guide data is shared as creative commons license CC BY-SA 3.0 and so is this code \n",
    "\n",
    "[![Creative Commons](https://wiki.zynthian.org/resources/assets/licenses/cc-by-sa.png)](https://creativecommons.org/licenses/by-sa/3.0/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "First the Zynthian focused information need to get downloaded, cleaned and prepared so that they eventually can get ranked and sorted by relevance of arbitrary questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e3e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d397132",
   "metadata": {},
   "source": [
    "Define notebook wide common settings for interacting with OpenAI's model.\n",
    "\n",
    "__Important Note__: please add your API key to the `open_ai.api_key` file or assign it directly to the `key_str` parameter below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "with open(\"../open_ai.api_key\", \"r\") as keyfile:\n",
    "    key_str = keyfile.read().replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\" \", \"\")\n",
    "    assert len(key_str) > 0, \"Can't continue without specifying a API key for OpenAI\"\n",
    "\n",
    "CLIENT = openai.OpenAI(api_key=key_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23811553",
   "metadata": {},
   "source": [
    "### Get the raw context data\n",
    "\n",
    "Zynthian offers a Wiki where the user guides can be fetched from. This HTML data needs to be converted into human readable strings, and cleaned from dublicates or even empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22844f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V5 |V4 |Touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zynthian Oram is the most recent version of zy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is strongly recommended that you read secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This guide is a living document, subject to fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fundamental building block of zynthian's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>and some example drivers here:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>zynthian-ui/zyngine/ctrldev/ · GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>All drivers must inherit from zynthian_ctrldev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Quite simple, right? This is for basic “generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>If you kind-of-understand this, you shouldn’t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0                                        V5 |V4 |Touch\n",
       "1    Zynthian Oram is the most recent version of zy...\n",
       "2    It is strongly recommended that you read secti...\n",
       "3    This guide is a living document, subject to fr...\n",
       "4    The fundamental building block of zynthian's s...\n",
       "..                                                 ...\n",
       "527                     and some example drivers here:\n",
       "528              zynthian-ui/zyngine/ctrldev/ · GitHub\n",
       "529  All drivers must inherit from zynthian_ctrldev...\n",
       "530  Quite simple, right? This is for basic “generi...\n",
       "532  If you kind-of-understand this, you shouldn’t ...\n",
       "\n",
       "[413 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_zynthian_context() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function provides essential Zynthian user guide information, \n",
    "    extracted from all <p></p> sections of its Wiki.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        pd.DataFrame: cleaned DataFrame with the extracted data in the \"text\" column name\n",
    "    \"\"\"\n",
    "    \n",
    "    # define set of webpages with user guides\n",
    "    landing_page = \"https://wiki.zynthian.org/index.php\"\n",
    "    user_guide_pages =[\n",
    "        \"Zynthian_UI_User%27s_Guide_-_Oram\",\n",
    "        \"ZynSeq_User_Guide\",\n",
    "        \"ZynSampler_User_Guide\",\n",
    "        \"Web_Configuration_User_Guide\",\n",
    "        \"Supported_plug_%26_play_MIDI_controllers\",\n",
    "    ]\n",
    "\n",
    "    # download & extract information from said web pages\n",
    "    all_paragraphs = list()\n",
    "    for user_guide_page in user_guide_pages:\n",
    "        subpage_response = requests.get(os.path.join(landing_page, user_guide_page))\n",
    "        soup = BeautifulSoup(subpage_response.text)\n",
    "        user_guide_p = soup.find_all(\"p\")    \n",
    "\n",
    "        for cur_p in user_guide_p:\n",
    "            all_paragraphs.append(cur_p.text.replace(\"\\n\", \"\"))\n",
    "\n",
    "\n",
    "    # turn it to a dataframe and apply data cleaning\n",
    "    df = pd.DataFrame()\n",
    "    df[\"text\"] = all_paragraphs\n",
    "    df = df[df[\"text\"] != \"\"]\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "CONTEXT_DF = extract_zynthian_context()\n",
    "CONTEXT_DF  # let's peek into the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Query Completion\n",
    "\n",
    "In this section the mechanisms are prepared in order to provide a prompt with a meaningful context, where the LLM can extract valuable information for the given user question.\n",
    "\n",
    "### Calculating Embeddings\n",
    "\n",
    "Embeddings are necessary for model inference but we're also using it to compare the similarity of a given user-question with the Zynthian user-guides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d04eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V5 |V4 |Touch</td>\n",
       "      <td>[-0.009096662513911724, -0.007616293150931597,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zynthian Oram is the most recent version of zy...</td>\n",
       "      <td>[-0.029481329023838043, -0.016066910699009895,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is strongly recommended that you read secti...</td>\n",
       "      <td>[-0.010746555402874947, 0.010111996904015541, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This guide is a living document, subject to fr...</td>\n",
       "      <td>[-0.0006172802532091737, -0.000813496182672679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fundamental building block of zynthian's s...</td>\n",
       "      <td>[-0.008485890924930573, -0.005419307388365269,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>and some example drivers here:</td>\n",
       "      <td>[-0.01640596054494381, 0.003860226133838296, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>zynthian-ui/zyngine/ctrldev/ · GitHub</td>\n",
       "      <td>[0.0013341867597773671, -0.008867095224559307,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>All drivers must inherit from zynthian_ctrldev...</td>\n",
       "      <td>[-0.0013864703942090273, 0.009447003714740276,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Quite simple, right? This is for basic “generi...</td>\n",
       "      <td>[0.013725951313972473, 0.016517670825123787, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>If you kind-of-understand this, you shouldn’t ...</td>\n",
       "      <td>[0.001430898322723806, -0.0033432997297495604,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0                                        V5 |V4 |Touch   \n",
       "1    Zynthian Oram is the most recent version of zy...   \n",
       "2    It is strongly recommended that you read secti...   \n",
       "3    This guide is a living document, subject to fr...   \n",
       "4    The fundamental building block of zynthian's s...   \n",
       "..                                                 ...   \n",
       "527                     and some example drivers here:   \n",
       "528              zynthian-ui/zyngine/ctrldev/ · GitHub   \n",
       "529  All drivers must inherit from zynthian_ctrldev...   \n",
       "530  Quite simple, right? This is for basic “generi...   \n",
       "532  If you kind-of-understand this, you shouldn’t ...   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [-0.009096662513911724, -0.007616293150931597,...  \n",
       "1    [-0.029481329023838043, -0.016066910699009895,...  \n",
       "2    [-0.010746555402874947, 0.010111996904015541, ...  \n",
       "3    [-0.0006172802532091737, -0.000813496182672679...  \n",
       "4    [-0.008485890924930573, -0.005419307388365269,...  \n",
       "..                                                 ...  \n",
       "527  [-0.01640596054494381, 0.003860226133838296, 0...  \n",
       "528  [0.0013341867597773671, -0.008867095224559307,...  \n",
       "529  [-0.0013864703942090273, 0.009447003714740276,...  \n",
       "530  [0.013725951313972473, 0.016517670825123787, -...  \n",
       "532  [0.001430898322723806, -0.0033432997297495604,...  \n",
       "\n",
       "[413 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attach_embeddings(df: pd.DataFrame, embedding_model_name:str, batch_size=100, client:openai.OpenAI=CLIENT) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a DataFrame with raw context information and calculates its embeddings and returns the updated frame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with human readable strings in column \"text\" that should be encoded\n",
    "        embedding_model_name: in what manner OpenAI should encode the data\n",
    "        batch_size: the amount of data that should be transmitted to the API at once\n",
    "        client: the OpenAI API handle\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with \"text\" and \"embedding\" columns\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = []\n",
    "    # iterate batch-wise to avoid API-overstraining\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        \n",
    "        # Actual embeddings will be calculated by OpenAI and applied for via its API\n",
    "        response = client.embeddings.create(\n",
    "            input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "            model=embedding_model_name).data\n",
    "\n",
    "        # Turn OpenAI packet into a list of embeddings\n",
    "        for response_data in response:\n",
    "            embeddings.append(response_data.embedding)\n",
    "\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df    \n",
    "\n",
    "CONTEXT_WITH_EMBEDDINGS_DF = attach_embeddings(CONTEXT_DF, EMBEDDING_MODEL_NAME)\n",
    "CONTEXT_WITH_EMBEDDINGS_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce287761",
   "metadata": {},
   "source": [
    "### Prepare temporary context\n",
    "\n",
    "The user guide information was downloaded and stored in an arbitrary fashion. OpenAI's model interface is limited by the total number of tokens in a prompt. It's because of this we can't use the full extracted information and have to prepare a subset of most relevant information. This can be achieved by encoding embeddings of the context paragraphs and measure its likeliness to the encoded question like in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82a45a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is known about tempo?\n",
      "\n",
      "[info] Unorderd DataFrame\n",
      "0                                        V5 |V4 |Touch\n",
      "1    Zynthian Oram is the most recent version of zy...\n",
      "2    It is strongly recommended that you read secti...\n",
      "Name: text, dtype: object\n",
      "\n",
      "[info] DataFrame ordered by relevance\n",
      "278    The current tempo is saved and loaded with eac...\n",
      "277    Tempo is the rate at which the sequencer plays...\n",
      "253    Tempo may be adjusted using the SNAPSHOT encod...\n",
      "Name: text, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_context(\n",
    "        question: str, \n",
    "        df: pd.DataFrame, \n",
    "        embedding_model_name: str,\n",
    "        client: openai.OpenAI=CLIENT) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes the unordered context data and orders it by relevance \n",
    "    according to the given question.\n",
    "    \n",
    "    Args:\n",
    "        question: the string that is used to order the dataset by likeliness\n",
    "        df: the unordered DataFrame with \"text\" and \"embeddings\" columns\n",
    "        embedding_model_name: in what manner OpenAI should encode the data\n",
    "        client:the OpenAI API handle\n",
    "    Returns:\n",
    "        pd.DataFrame: a DataFrame sorted by relevance to the given question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call OpenAI's API to calculate the relevance parameter and attach it to the dataframe\n",
    "    querry_embedding = client.embeddings.create(input=question, model=embedding_model_name).data[0].embedding\n",
    "    \n",
    "    df[\"distances\"] = [cosine_similarity([querry_embedding], [content_embedding]) \n",
    "                       for content_embedding in df[\"embeddings\"]]\n",
    "\n",
    "    # Take the unordered DataFrame and sort it by the just calculcated relevance parameter\n",
    "    return df.sort_values(\"distances\", ascending=False)\n",
    "\n",
    "TEST_QUESTION = \"What is known about tempo?\"\n",
    "RELEVANT_CONTEXT = get_relevant_context(TEST_QUESTION, CONTEXT_WITH_EMBEDDINGS_DF, EMBEDDING_MODEL_NAME)\n",
    "\n",
    "N_CHECK_ENTRIES = 3\n",
    "print(f\"Q: {TEST_QUESTION}\\n\")\n",
    "print(f\"[info] Unorderd DataFrame\\n{CONTEXT_WITH_EMBEDDINGS_DF[0:N_CHECK_ENTRIES]['text']}\\n\")\n",
    "print(f\"[info] DataFrame ordered by relevance\\n{RELEVANT_CONTEXT[0:N_CHECK_ENTRIES]['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bac9ab",
   "metadata": {},
   "source": [
    "## Prompt generator\n",
    "\n",
    "In order that we can use the chat bot with the extended context information, a standardized way of creating its prompt is being prepared here. It carefully watches the number of utilized token doesn't exceed its limits, puts the relevant context and eventually the actual query into one large string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Making a prompt for: What is known about tempo?\n",
      "[info] Limited context to 30/413 paragraphs\n",
      "[info] Created following prompt:\n",
      "===========================\n",
      "\n",
      "Context:\n",
      "The current tempo is saved and loaded with each snapshot.\n",
      "---\n",
      "Tempo is the rate at which the sequencer plays back notes measured in beats per minutes (BPM). By default ZynSeq plays sequences at 120 BPM. Adjust Tempo with the SNAPSHOT encoder. The tempo is briefly displayed in the title bar. There is also a menu option to adjust tempo.\n",
      "---\n",
      "Tempo may be adjusted using the SNAPSHOT encoder or by selecting \"Tempo\" from the menu.\n",
      "---\n",
      "ZynSeq allows tempo to be adjusted from 1.0 BPM to 420.0 BPM in 0.1 BPM steps. Tempo may also be altered by external modules, e.g. MIDI player.\n",
      "---\n",
      "Knob K3 is used to adjust the tempo. When rotated, the Zynthian tempo screen will be shown briefly. This tempo setting is synchronized with the MPK. \n",
      "---\n",
      "For instance, if you are in the mixer view and short-push OPT/ADMIN, the Main menu will be opened. If you short-push it again, the Admin menu will be opened. Then, if you bold-push the MIX/LEVEL button, the Audio Levels view will be opened. You push \"metronome\" button and the Tempo settings view will be opened. If you tap-it several times, the tempo BPM will be changed, e.g. tap twice per second to set tempo to 120BPM.\n",
      "---\n",
      "Each sequence has a timebase track which may have tempo and time signature (beats per bar) events. These will influence all playback. The ability to manipulate sequence timebase events is not yet implemented.\n",
      "---\n",
      "View buttons are outlined on green in the image and they allow direct access to the main views. Most of these buttons have 2 different views assigned, with a horizontal line separating two printed labels. The primary view is printed at top and the secondary view is printed at bottom. The \"metronome\" button is the exception, as it's the tap-tempo button. You push it once to access the tempo settings view, but you can tap-it several times to change the tempo BPM. Try it!\n",
      "---\n",
      "Sequences may be configured to stay synchronised with shorter phrases pausing and starting again at start of bar or polymeters may be implemented with shorter patterns driftting across longer ones.\n",
      "---\n",
      "Zynthian allows the beats per bar to be configured but not the beat type. All beats are assumed to be quarter notes and the default beats per bar is 4, hence a 4/4 time signature. The beats per bar may be adjusted from a menu option and can be set to any value between 1 and 64. The most significant behaviour that beats per bar influences is the sync point. The sync point is the point at which a sequence starts, loops or stops and is synonymous with start of bar hence the beats per bar defines the quantity of beats between sync points which in turn defines the rate at which sequences will loop.\n",
      "---\n",
      "There is a pitch control that adjusts the pitch of the audio without changing its speed.\n",
      "---\n",
      "There is a speed control that adjusts the speed of the audio without changing its pitch.\n",
      "---\n",
      "NOTE: The MPK resolution is 1BPM, but Zynthian is 0.1BPM; take this into account to avoid drifting. \n",
      "---\n",
      "There are vertical white lines indicating the beats. The quantity of beats in the pattern may be adjusted from the menu as well as the quantity of steps in each beat. This allows the duration and quantisation level of the pattern to be adjusted. Changing the beats in pattern will change the pattern duration. Changing the steps per beat will change the pattern resolution.\n",
      "---\n",
      "ZynSeq uses JACK timebase for its timing. Transport control and adjustment of tempo may be made by external JACK clients. Those clients may also use the same timebase. This means that ZynSeq can synchronise with other modules within Zynthian, e.g. synth engine LFO, arpeggiators, etc. It also means that other modules may control ZynSeq playback to some degree. ZynSeq acts as the timebase master, i.e. the concept of bars, beats and ticks (fractions of beats) and consequently tempo (BPM) is provided by ZynSeq. There is currently no mechanism to lock to external MIDI clock but a Zynthian MIDI effects layer may be used to create MIDI clock output. There is a plan to improve this support in a future update.\n",
      "---\n",
      "You may wish to use one sequence as a click track by having a simple percusion sound looping. You could use a similar track in oneshot mode as the count-in for a song, pressing pads for the first bars of the song whilst the count-in playing or maybe use a silent sequence for the same purpose to allow manual synchronisation of several sequences at the start of a performance.\n",
      "---\n",
      "To preview a pattern, start or pause the transport by pressing the play button, learn/shot encoder or tapping the status area. A coloured bar at the bottom of the view will move left to right to indicate the position of the playhead and any notes entered in the pattern will be sent to the zynthian's engines. To stop and recue to the start of the pattern, bold press. Playback speed (Tempo) can be adjusted with the encoder 1 or by selecting \"Tempo\" from the menu.\n",
      "---\n",
      "The current value of beats per bar is saved with the snapshot and restored when a snapshot is loaded. The beats per bar may also be varied during sequence playback and will be added to a sequence within the arranger. This functionality is currently disabled.\n",
      "---\n",
      "MIDI learning\n",
      "---\n",
      "There is a control to adjust the beats in the sample. This may be used to synchronise the sample with sequencer playback. If the beats has been set to a non-zero value, the marker menu has an option to create that quantity of equally spaced cue markers.\n",
      "---\n",
      "MIDI triggered playback is affected by an AHDSR envelope with controls for:\n",
      "---\n",
      "The playback indication icon changes to red to indicate it is stopping and then disappears to indicate it has stopped. Most play modes will continue to play the sequence until the next sync point. A sync point may be thought of as the start or end of a bar, indeed their spacing is set using the menu option Beats per bar.\n",
      "---\n",
      "A pattern may be exported as a standard MIDI file. The tempo and all the notes within the pattern on its current channel will be exported to a file in Zynthian's capture location which may be accessed via webconf. The filename will consist of the pattern number and a date / time stamp of when the export occured, e.g. pattern2_2021-02-18 15:15:19.335558.mid.\n",
      "---\n",
      "There is a varispeed control that adjusts both speed and pitch, like varying the speed of a tape machine. This can also be used like a scrub control, allowing both forward and reverse playback.\n",
      "---\n",
      "Each note may be adjusted to have different duration, velocity, etc. To adjust a note's parameters, bold SELECT to show the parameter editor. Use encoder 4 (or onscreen buttons if enabled) to select the parameter to adjust. The options are:\n",
      "---\n",
      "PatternA pattern contiains zero or more events. Each pattern has a duration in steps and may include as many simultaneous (polyphonic) notes as desired on each step. We will see how patterns are manipulated in the  Pattern Editor section\n",
      "---\n",
      "A Sync point is a location within playback at which sequences will loop and / or group sequential play will change to another sequence. Sync points are synonymous with bars in traditional music notation. See section on time signature.\n",
      "---\n",
      "Within the scrollbar is an infomation display. By default this shows the duration of the sample. There is a control to adjust the displayed info:\n",
      "---\n",
      "There is a grid on the right called the Step Grid. On the left is a representation of a piano keyboard, scale or drum map. Each row represents a note and each column in the step grid represents a step in the sequence.\n",
      "---\n",
      "As you can see in the image, this mode mimics the Zynthian V5 hardware interface. The upper four buttons are OPT/ADMIN, MIX/LEVEL, CTRL/PRESET and ZS3/SHOT. Next row is ALT, METRONOME and PAD/STEP. The four buttons at the right side (in white) are F1 to F4. In this mode, transport is handled by PLAY/PAUSE and RECORD buttons, and the transport pads are only to show playback/recording status. Navigation buttons are UP, DOWN, LEFT, RIGHT, (in yellow) BACK/NO (in red) and SEL/YES (in green). For the directional keys, you can also use the track keys labelled as such. \n",
      "---\n",
      "Question:\n",
      "What is known about tempo?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(question, \n",
    "                context_df,\n",
    "                embedding_model_name: str = EMBEDDING_MODEL_NAME,\n",
    "                max_question_len=100, \n",
    "                max_prompt_tokens=1800,\n",
    "                verbose=False,\n",
    "                tokenizer=TOKENIZER):\n",
    "    \"\"\"\n",
    "    This function provides standardized prompts. The context is ordered by relevance to the user query.\n",
    "    \n",
    "    Args:\n",
    "        question: the string that is used to order the dataset by likeliness\n",
    "        context_df: the unordered DataFrame with \"text\" and \"embeddings\" columns\n",
    "        embedding_model_name: in what manner OpenAI should encode the data\n",
    "        max_question_len: the number of characters shouldn't exceed this number\n",
    "        max_prompt_tokens: not more than this number of tokens will be passed to OpenAI and exiting\n",
    "            early the context creation if this value is exceeded\n",
    "        verbose: print user feedback during processing\n",
    "        tokenizer: the tiktoken callback function to turn raw strings into tokens.\n",
    "    Returns:\n",
    "        str: the prompt with relevant context and user question\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(question) < max_question_len, f\"Your question is too long, please rephrase to use less than {max_question_len} charachters.\"\n",
    "    if verbose:\n",
    "        print(f\"[info] Making a prompt for: {question}\")\n",
    "        \n",
    "    # set up raw layout of prompt\n",
    "    prompt_context = \"Context:\\n\"\n",
    "    prompt_question = f\"Question:\\n{question}\"\n",
    "    relevant_context = get_relevant_context(question, context_df, embedding_model_name)\n",
    "    \n",
    "    # begin assembling the relevant context as long as there are unused tokens left\n",
    "    remaining_tokens = len(tokenizer.encode(prompt_context)) + len(tokenizer.encode(prompt_question))\n",
    "    for idx, text_element in enumerate(relevant_context[\"text\"]):\n",
    "        remaining_tokens += len(tokenizer.encode(text_element))\n",
    "        if remaining_tokens > max_prompt_tokens:  # working with a soft limit\n",
    "            if verbose:\n",
    "                print(f\"[info] Limited context to {idx}/{relevant_context.shape[0]} paragraphs\")\n",
    "            break\n",
    "        else:\n",
    "            prompt_context += f\"{text_element}\\n---\\n\"\n",
    "    \n",
    "    # complete full prompt\n",
    "    prompt = prompt_context + prompt_question\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"[info] Created following prompt:\")\n",
    "        print(f\"===========================\\n\\n{prompt}\\n\\n\")\n",
    "\n",
    "    return prompt\n",
    "\n",
    "_ = make_prompt(TEST_QUESTION, CONTEXT_WITH_EMBEDDINGS_DF, EMBEDDING_MODEL_NAME, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03994d",
   "metadata": {},
   "source": [
    "### Prompt submission\n",
    "After all preparations have been made to provide a prompt of higher quality, a standardized way of querying OpenAI's model with a prompt is established first before eventually running a test comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(prompt:str, \n",
    "               client: openai.OpenAI = CLIENT, \n",
    "               model:str = COMPLETION_MODEL_NAME, \n",
    "               max_answer_tokens:int=500) -> str:\n",
    "    \"\"\"\n",
    "    This submits arbitrary prompts to OpenAI's Completion interface and \n",
    "    returns the most likely estimate as a string\n",
    "    \n",
    "    Args:\n",
    "        prompt: the query that will be passed to the model\n",
    "        client: the OpenAI API handle\n",
    "        completion_model_name: the model that the query should interfere with\n",
    "        max_answer_tokens: limitation to avoid overstraining OpenAI services\n",
    "    Returns:\n",
    "        str: the most likely answer for the input question    \n",
    "    \"\"\"  \n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_tokens=max_answer_tokens)\n",
    "        # return most likely answer\n",
    "        return response.choices[0].message.content.strip()\n",
    "    # Embedding this in a sand box if for instance the API is not reachable.\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Chatbot Performance Demonstration\n",
    "\n",
    "Here the performance is demonstrated by two questions:\n",
    "\n",
    "- the vanilla modus just takes the question and queries OpenAI's Completion model.\n",
    "- the context modus takes the question and adds, relative to the given question, relevant information from the Zynthian user guides.\n",
    "\n",
    "Two questions are being picked that are less likely to be answered by general knowledge of synthesizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "This question covers a couple of paragraphs referencing the unit, that makes guessing harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f0736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"List all functions of the 'short-push' button in Zynthian.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Zynthian, the 'short-push' button typically has several functions depending on the context:\n",
      "\n",
      "1. Select: The 'short-push' button can be used to select items or options within the Zynthian interface.\n",
      "\n",
      "2. Confirm: The button can be used to confirm selections or actions, such as saving settings or applying changes.\n",
      "\n",
      "3. Menu access: In some menus, the 'short-push' button may be used to access additional options or sub-menus.\n",
      "\n",
      "4. Play/Stop: In certain instruments or applications, the 'short-push' button may function as a play/stop control.\n",
      "\n",
      "5. Navigation: The 'short-push' button can also be used for navigation purposes, such as scrolling through lists or pages.\n",
      "\n",
      "These are some common functions associated with the 'short-push' button in Zynthian, but the actual functions may vary depending on the specific configuration or setup of the Zynthian system.\n"
     ]
    }
   ],
   "source": [
    "vanilla_prompt = question\n",
    "print(ask_openai(vanilla_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'short-push' button functions in Zynthian are as follows:\n",
      "\n",
      "1. Accessing the classic zynthian workflow (V1-V4) based on the 4 knobs' switches.\n",
      "2. Show onscreen buttons after selecting certain menu items, allowing adjustments of parameters using the touchscreen interface.\n",
      "3. Redefining the short-push functionality of transport, arrows, and F1-F4 buttons.\n",
      "4. Providing a summary of connected hardware MIDI INPUT/OUTPUT ports.\n",
      "5. Configuring the touchscreen display.\n",
      "6. Assigning midi note values to control the Zynthian UI.\n",
      "7. Reviewing presets across all instruments and effects in the Zynthian box.\n",
      "8. Updating the Zynthian software.\n",
      "9. Browsing and selecting options in the main menu selector view.\n",
      "10. Enabling MIDI learning for all available controls.\n",
      "11. Switching back to the default mode to adjust chain settings in the mixer interface.\n",
      "12. Accessing the Zynthian box from a browser.\n",
      "13. Controlling Zynthian's step sequencer and pattern editor when in the corresponding mode.\n"
     ]
    }
   ],
   "source": [
    "context_prompt = make_prompt(question, CONTEXT_WITH_EMBEDDINGS_DF)\n",
    "print(ask_openai(context_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "For verification see https://wiki.zynthian.org/index.php/ZynSeq_User_Guide#Time_Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Zynthian, the most significant behavior that influences the beats per bar is the time signature. The time signature indicates how many beats are in each bar of music. For example, a time signature of 4/4 means there are 4 beats in each bar, while a time signature of 3/4 means there are 3 beats in each bar. By setting the time signature in Zynthian, you can determine the number of beats per bar and create a rhythmic structure for your music.\n"
     ]
    }
   ],
   "source": [
    "question = \"In Zynthian: what is the most significant behaviour that influences beats per bar ?\"\n",
    "vanilla_prompt = question\n",
    "print(ask_openai(vanilla_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most significant behavior that influences beats per bar in Zynthian is the sync point. The sync point is the point at which a sequence starts, loops, or stops and is synonymous with the start of a bar. The beats per bar defines the quantity of beats between sync points, which in turn defines the rate at which sequences will loop. Adjusting the beats per bar affects how the sequences are synchronized and looped within Zynthian.\n"
     ]
    }
   ],
   "source": [
    "context_prompt = make_prompt(question, CONTEXT_WITH_EMBEDDINGS_DF)\n",
    "print(ask_openai(context_prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delme",
   "language": "python",
   "name": "delme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
